# import argparse
# import os

# import mlflow
from sklearn.metrics import accuracy_score # , auc, confusion_matrix, f1_score, roc_curve
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder

# from nmrcraft.analysis.plotting import plot_confusion_matrix, plot_roc_curve

# Assuming these are your custom modules
from nmrcraft.data.dataset import load_data
# from nmrcraft.models.models import load_model
from nmrcraft.utils.set_seed import set_seed

# Test hyperparameter tuning
from sklearn.ensemble import RandomForestClassifier
from hyperopt import hp, fmin, tpe, Trials, STATUS_OK

set_seed(42)

dataset = load_data()
dataset = dataset.sample(frac=0.01)

feature_columns = [
    "M_sigma11_ppm",
    "M_sigma22_ppm",
    "M_sigma33_ppm",
    "E_sigma11_ppm",
    "E_sigma22_ppm",
    "E_sigma33_ppm",
]

X = dataset[feature_columns].to_numpy()
y_label = dataset["metal"].to_numpy()

label_encoder = LabelEncoder()
label_encoder.fit(["Mo", "W"]) 
y = label_encoder.transform(y_label)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


space = {
    "n_estimators": hp.choice("n_estimators", range(10, 1000, 10)),
    "criterion": hp.choice("criterion", ["gini", "entropy"]),
    "max_depth": hp.choice("max_depth", range(10, 1200, 10)),
    "min_samples_split": hp.uniform("min_samples_split", 0, 1),
    "min_samples_leaf": hp.uniform("min_samples_leaf", 0, 0.5),
    "max_features": hp.choice("max_features", ["sqrt", "log2", None]),
    }

def objective(space):
    model = RandomForestClassifier(
        n_estimators=space["n_estimators"],
        criterion=space["criterion"],
        max_depth=space["max_depth"],
        min_samples_split=space["min_samples_split"],
        min_samples_leaf=space["min_samples_leaf"],
        max_features=space["max_features"],
    )

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    score = accuracy_score(y_test, y_pred)
    # score = cross_val_score(model, X_train, y_train, cv=4).mean()
    return {"loss": -score, "status": STATUS_OK}

print("\nStarting hyperparameter tuning...")
trials = Trials()
best = fmin(
    fn=objective, 
    space=space,
    algo=tpe.suggest,
    max_evals=100,
    trials=trials,
)

print(f"\nBest hyperparameters found:\n{best}")